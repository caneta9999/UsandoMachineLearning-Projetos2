{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LSWesOuCRNk"
      },
      "outputs": [],
      "source": [
        "#Credits and Thanks\n",
        "#https://www.youtube.com/watch?v=bD6V3rcr_54\n",
        "#https://www.gymlibrary.dev/content/environment_creation/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dbXAqepCxwt"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow==2.3.0\n",
        "!pip install gym\n",
        "!pip install keras\n",
        "!pip install keras-rl2\n",
        "!pip install stable-baselines3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "tPybqUkUDD9A"
      },
      "outputs": [],
      "source": [
        "from gym import Env\n",
        "from gym.spaces import Discrete, Box\n",
        "from rl.agents import DQNAgent\n",
        "from rl.memory import SequentialMemory\n",
        "from rl.policy import BoltzmannQPolicy\n",
        "from stable_baselines3 import DQN\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_quyvuBYNKm"
      },
      "source": [
        "#Glass of Water"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sam9-7F3DvOG"
      },
      "outputs": [],
      "source": [
        "class GlassOfWater(Env):\n",
        "    def __init__(self):\n",
        "        # 0,1,2,3 -> put water\n",
        "        self.action_space = Discrete(4)\n",
        "\n",
        "        # glass filling percentage\n",
        "        self.observation_space = Box(low=np.array([0]), high=np.array([100]))\n",
        "\n",
        "        self.best_reward = 1000\n",
        "\n",
        "        # how much water the person wants\n",
        "        self.preference = random.randint(40,80)\n",
        "        self.state = 0\n",
        "        self.glass_length = 5\n",
        "        \n",
        "    def step(self, action):\n",
        "        water = 0\n",
        "        if action == 0:\n",
        "          water += 2 * random.uniform(0.5, 1.5)\n",
        "        elif action == 1:\n",
        "          water += 5 * random.uniform(0.5, 1.5)\n",
        "        elif action == 2:\n",
        "          water += 10 * random.uniform(0.5, 1.5)\n",
        "        else:\n",
        "          water += 20 * random.uniform(0.5, 1.5)\n",
        "        self.state += water\n",
        "        self.glass_length -=1\n",
        "\n",
        "        done = False\n",
        "        reward = 0\n",
        "        info = {}\n",
        "        if self.state >= self.preference:\n",
        "          done = True\n",
        "          reward += self.best_reward - (self.state - self.preference)*15\n",
        "        elif self.glass_length == 0:\n",
        "          done = True\n",
        "        else:\n",
        "          done = False\n",
        "          reward = self.state - self.preference\n",
        "        \n",
        "        return self.state, reward, done, info\n",
        "\n",
        "    def render(self):\n",
        "      pass\n",
        "\n",
        "    def reset(self):\n",
        "      self.preference = random.randint(40,80)\n",
        "      self.state = 0\n",
        "      self.glass_length = 5\n",
        "      return self.state     \n",
        "env = GlassOfWater()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JX3-gwpsJIM6",
        "outputId": "bb8b93ca-60b9-447a-9b80-7bdd12759524"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode:1 - Score:-184.91360858546136\n",
            "Episode:2 - Score:-252.27794540058915\n",
            "Episode:3 - Score:-114.72656173355657\n",
            "Episode:4 - Score:-179.78512520514792\n",
            "Episode:5 - Score:-256.3751694098613\n",
            "Episode:6 - Score:914.9084458409337\n",
            "Episode:7 - Score:-194.11317478040883\n",
            "Episode:8 - Score:-119.9327830273551\n",
            "Episode:9 - Score:-180.45832462936113\n",
            "Episode:10 - Score:-175.3842227775886\n",
            "Episode:11 - Score:-112.5761304787597\n",
            "Episode:12 - Score:-144.13679479797347\n",
            "Episode:13 - Score:-209.36442630861802\n",
            "Episode:14 - Score:856.9569203749451\n"
          ]
        }
      ],
      "source": [
        "episodes = 14\n",
        "for episode in range(1, episodes+1):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    score = 0 \n",
        "    \n",
        "    while not done:\n",
        "        action = env.action_space.sample()\n",
        "        n_state, reward, done, info = env.step(action)\n",
        "        score+=reward\n",
        "    print('Episode:{} - Score:{}'.format(episode, score))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuJsHIwlWqql"
      },
      "outputs": [],
      "source": [
        "states = env.observation_space.shape\n",
        "actions = env.action_space.n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37z7zCkfMu6e"
      },
      "source": [
        "# RL Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsRKY7qqWuKV"
      },
      "outputs": [],
      "source": [
        "def build_model(states, actions):\n",
        "    model = Sequential()    \n",
        "    model.add(Dense(24, activation='relu', input_shape=states))\n",
        "    model.add(Dense(24, activation='relu'))\n",
        "    model.add(Dense(24, activation='relu'))\n",
        "    model.add(Dense(actions, activation='linear'))\n",
        "    return model\n",
        "model = build_model(states, actions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4OPhRJDW1zy"
      },
      "outputs": [],
      "source": [
        "def build_agent(model, actions):\n",
        "    policy = BoltzmannQPolicy()\n",
        "    memory = SequentialMemory(limit=50000, window_length=1)\n",
        "    dqn = DQNAgent(model=model, memory=memory, policy=policy, \n",
        "                  nb_actions=actions, nb_steps_warmup=30, target_model_update=1e-2)\n",
        "    return dqn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jp1r4RPmW3kq"
      },
      "outputs": [],
      "source": [
        "dqn = build_agent(model, actions)\n",
        "dqn.compile(Adam(), metrics=['mae'])\n",
        "dqn.fit(env, nb_steps=50000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__QVm6mDNYMk"
      },
      "outputs": [],
      "source": [
        "env.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghUN-FzJNKGp",
        "outputId": "2f6b0152-9d52-481a-a6c2-9c0c287f1d6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing for 50 episodes ...\n",
            "Episode 1: reward: 874.746, steps: 4\n",
            "Episode 2: reward: 896.347, steps: 3\n",
            "Episode 3: reward: 669.093, steps: 4\n",
            "Episode 4: reward: 705.724, steps: 3\n",
            "Episode 5: reward: 733.878, steps: 3\n",
            "Episode 6: reward: 676.011, steps: 4\n",
            "Episode 7: reward: 890.349, steps: 3\n",
            "Episode 8: reward: 677.555, steps: 4\n",
            "Episode 9: reward: 805.981, steps: 3\n",
            "Episode 10: reward: 781.968, steps: 3\n",
            "Episode 11: reward: 859.798, steps: 3\n",
            "Episode 12: reward: 919.264, steps: 3\n",
            "Episode 13: reward: 862.949, steps: 3\n",
            "Episode 14: reward: 822.272, steps: 3\n",
            "Episode 15: reward: 833.868, steps: 3\n",
            "Episode 16: reward: 873.779, steps: 2\n",
            "Episode 17: reward: 905.316, steps: 3\n",
            "Episode 18: reward: 786.581, steps: 5\n",
            "Episode 19: reward: 848.537, steps: 3\n",
            "Episode 20: reward: 844.711, steps: 3\n",
            "Episode 21: reward: 685.528, steps: 3\n",
            "Episode 22: reward: 657.347, steps: 4\n",
            "Episode 23: reward: 790.974, steps: 3\n",
            "Episode 24: reward: 765.872, steps: 4\n",
            "Episode 25: reward: 940.274, steps: 2\n",
            "Episode 26: reward: 561.280, steps: 3\n",
            "Episode 27: reward: 712.158, steps: 3\n",
            "Episode 28: reward: 617.810, steps: 4\n",
            "Episode 29: reward: 704.623, steps: 3\n",
            "Episode 30: reward: 905.369, steps: 3\n",
            "Episode 31: reward: 899.131, steps: 4\n",
            "Episode 32: reward: 905.586, steps: 4\n",
            "Episode 33: reward: 726.271, steps: 3\n",
            "Episode 34: reward: 772.423, steps: 4\n",
            "Episode 35: reward: 772.376, steps: 3\n",
            "Episode 36: reward: 632.511, steps: 3\n",
            "Episode 37: reward: 899.731, steps: 3\n",
            "Episode 38: reward: 912.251, steps: 3\n",
            "Episode 39: reward: 730.872, steps: 3\n",
            "Episode 40: reward: 978.996, steps: 2\n",
            "Episode 41: reward: 650.827, steps: 4\n",
            "Episode 42: reward: 776.856, steps: 4\n",
            "Episode 43: reward: 616.222, steps: 4\n",
            "Episode 44: reward: 514.634, steps: 5\n",
            "Episode 45: reward: 788.798, steps: 4\n",
            "Episode 46: reward: 829.972, steps: 4\n",
            "Episode 47: reward: 762.083, steps: 3\n",
            "Episode 48: reward: 859.170, steps: 3\n",
            "Episode 49: reward: 880.355, steps: 4\n",
            "Episode 50: reward: 569.367, steps: 4\n",
            "Mean = 781.7679565890846\n"
          ]
        }
      ],
      "source": [
        "scores = dqn.test(env, nb_episodes=50, visualize=False)\n",
        "print(f\"Mean = {np.mean(scores.history['episode_reward'])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgivGQVdM4MF"
      },
      "source": [
        "# Stable Baselines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSpkwe15OFbe"
      },
      "outputs": [],
      "source": [
        "env.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ca0ndKlbNzuv"
      },
      "outputs": [],
      "source": [
        "model = DQN('MlpPolicy', DummyVecEnv([lambda: env]), verbose = 0)\n",
        "model.learn(total_timesteps=100000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzePQjeRRimr",
        "outputId": "45897379-e01b-461b-caac-c2895fb54033"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(782.826147825718, 104.70294774946038)"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate_policy(model, DummyVecEnv([lambda: env]), n_eval_episodes=50)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "68b7b2992015965862964422318784d011c46f0cefacf66fb4dc9ffbce81bd73"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
